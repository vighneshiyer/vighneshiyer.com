+++
title = "All Hail the Magic Conch!"
date = 2025-09-27
draft = false
description = "The era of \"asking the model\" and vibe research"

[extra]
new = true
+++

## Prelude

Deep in the depths of the ocean, in Bikini Bottom, there was one Club Spongebob[^1].
High up on a tall tree, sits the clubhouse, occupied by a sponge and Patrick.

[^1]: [Season 3, Episode 42a](https://spongebob.fandom.com/wiki/Club_SpongeBob). Watch the episode please.

{{ image(path="club_spongebob_1.png", class="inset") }}

On this fine day, Squidward exits his [Moai](https://en.wikipedia.org/wiki/Moai) to see these two barnacle heads laughing it up in their treehouse.
Of course, there is nothing more irritating than their giggling.
And when Squidward was told he wouldn't "fit in" their club, he couldn't take it.
He had to join! And so up he went.

{{ gallery(images=[
    "club_spongebob_2-0.webp",
    "club_spongebob_2-1.webp",
], popout=false) }}

But once inside, he found out that, indeed, he couldn't physically "fit in" the clubhouse and was now squished next to Bob and Patrick.

{{ gallery(images=[
    "club_spongebob_3-0.webp",
    "club_spongebob_3-1.webp",
], popout=false) }}

Squidward, desperate to escape, reaches for a branch and tries to pull himself down.

{{ gallery(images=[
    "club_spongebob_4-0.webp",
    "club_spongebob_4-1.webp",
], popout=false) }}

As he's almost down, the branch rips apart, and the treehouse is launched into the sky (sea).
The clubhouse flies through the sea and comes crashing down in the thick Kelp Forest.

{{ gallery(images=[
    "club_spongebob_5-0.webp",
    "club_spongebob_5-1.webp",
    "club_spongebob_5-2.webp",
], popout=false) }}

Oh no, Squid is trapped. Lost. Hundreds of miles from civilization.

{{ gallery(images=[
    "club_spongebob_6-0.webp",
    "club_spongebob_6-1.webp",
], popout=false) }}

He starts to panic. How can he escape these two morons now?

But luckily, Squidward is part of Club Spongebob, and they have one trick up their sleeve: *the Magic Conch*.

{{ image(path="club_spongebob_7.webp", class="inset", caption="The Magic Conch is here to save the day!") }}

> **Squidward**: You've got to be kidding! That is just a stupid toy! How can that possibly help us?!
>
> **SpongeBob**: [gasps] Squidward! We must never question the wisdom of the Magic Conch! The club always takes its advice before we do anything!
>
> **Patrick**: The shell knows all!

{{ gallery(images=[
    "club_spongebob_8-1.webp",
    "club_spongebob_8-0.webp",
], popout=false) }}

> **SpongeBob**: Oh, Magic Conch Shell. What do we need to do to get out of the Kelp Forest?
>
> **Magic Conch**: *Nothing*.
>
> **Patrick**: The shell has spoken!
>
> **Squidward**: *Nothing*?! We can't just sit here and do nothing!
>
> **Squidward**: I can't believe you two are gonna take advice from a toy!

{{ gallery(images=[
    "club_spongebob_9-0.webp",
    "club_spongebob_9-1.webp",
], popout=false, caption="Just do what the Conch tells you to do.") }}

Squidward thinks he's smarter than the Magic Conch, so he runs and runs to escape the forest, only to find out he's running in circles and is right back at Club Spongebob.
He sets up a camp with the resources he has while SpongeBob and Patrick continue to listen to the Conch.

{{ gallery(images=[
    "club_spongebob_10-0.webp",
    "club_spongebob_10-1.webp",
], popout=false, caption="Squidward is certain he's smarter than the Conch followers") }}

Right as Squidward was about to enjoy his roasted sea insect, a miracle falls from the sky, right into the camp of SpongeBob and Patrick!
What a gift from the Magic Conch!

{{ gallery(images=[
    "club_spongebob_11-0.webp",
    "club_spongebob_11-1.webp",
], popout=false, caption="The gift from the Conch has arrived!") }}

As SpongeBob and Patrick enjoy their feast, Squidward begs to be allowed to touch the food.
They inform Squid that *only the Conch* can approve his request.
And so he asks the Conch, again and again, "may I have something to eat?"

{{ gallery(images=[
    "club_spongebob_12-0.webp",
    "club_spongebob_12-1.webp",
], popout=false) }}

But he didn't give the Conch its due earlier, so the Conch only gives him a simple "no".
Squidward goes crazy as the Conch seems to be aware of his dismissal of its powers.

And then, someone cuts a path into the forest!

{{ gallery(images=[
    "club_spongebob_13-1.webp",
    "club_spongebob_13-0.webp",
], popout=false, caption="The Kelp Forest ranger has arrived to save Squidward!") }}

Squidward screams in delight &mdash; someone is here to save them!

{{ gallery(images=[
    "club_spongebob_14-1.webp",
    "club_spongebob_14-0.webp",
], popout=false) }}

But to Squid's dismay, the ranger also has a Conch of his own.

> **Kelp Forest Ranger**: All right, Magic Conch... what do we do now?
>
> **Magic Conch**: *Nothing*.
>
> **SpongeBob, Patrick, and Kelp Forest Ranger**: All hail the Magic Conch!

{{ gallery(images=[
    "club_spongebob_15-1.webp",
    "club_spongebob_15-0.webp",
], popout=false) }}

### Sound Familiar?

And so they sit, in silence, in devotion to the Conch, until another miracle falls from the sky.
Perhaps, if they ask the Conch again and again, it will give them the answer to their problem.
Perhaps, a new version of the Conch will do better than the old one.

Whenever you have a question, don't think, just ask the Conch[^2].
And whatever the Conch tells you, is what you should parrot to others and follow diligently.

[^2]: The Conch = a large language model (henceforth called "the model")

But, just because it worked for SpongeBob, doesn't mean it will work for you.
There is a growing mass of people who believe the Conch will enable them to do nothing, and that good things will fall out of the sky.

<!-- Patrick: The shell has spoken! The shell knows all! - Patrick Star -->

<!--
Bikini bottom, squid tried to join, flung into the forest, and to get out they reach for the model! Sound familiar? Ask the model and do what it says. Don't think further. Just because it worked for SpongeBob doesn't mean it will work for you ðŸ˜†. Do nothing and good things will happen and they will fall out of the sky lmao.
-->

## The Situation

There has been a lot said over the past two decades about how electronics can sap away our thinking powers.
When humans lose the ability to *be bored* and produce something from nothing, their mental faculties decay.
I believe Cal Newport put this phenomena into the public consciousness with his book "Deep Work"[^3] where he discusses how electronics, especially phones, have put humans in an unprecedented situation where they can go through life and *never* be bored.
Whatever attention span degradation phones have already caused has been or will soon be dwarfed by the advent of the model.

[^3]: I started hearing about the importance of boredom from 2016 or so when Newport's book was published

In the past two years, in addition to the phone, which can prevent even a few seconds of boredom from setting in, we now have "the model".
As people begin to use the model, they start by asking it a few questions about topics that they would have used a search engine for in the past.
However, as model dependency grows, people begin to outsource their *thinking* and even *thoughts* wholesale to the model.
I need not dwell on this point too much, since others have made it much better[^4].

[^4]: See the article ["The End of Thinking"](https://www.derekthompson.org/p/the-end-of-thinking) by Derek Thompson

<!--
Electronics have always reduced attention spans, and the test scores are going down year after year. Some of this is due to dysgenic breeding, others due to demographic shifts into populations with lower IQ, but in just the past 2 years, a lot can be attributed to the model. The highest performer won't be affected and they will actually be supercharged, but the rest will lump into the bottom mode.

The bimodal distribution of students, very smart first year ugrads that can learn themselves. Also morons who can't learn and just ask the model and produce garbage code they don't understand and can't explain.
-->

### Bimodal Undergrads

I've been in the university system for a long time. Almost certainly too long.
Every year, I get a sample of the current class of undergrads to examine &mdash; both from teaching classes and from advising them on research.
Year after year, the mean quality of undergrads has degraded &mdash; the average undergrad is increasingly motivated by money, status, and job prospects rather than any intrinsic interest in computer science.
However, this trend about averages says nothing about the extremes.

The mediocre undergrads are crashing to the level of the barely literate ones, while the elite undergrads can rival senior grad students in programming competence, inquisitiveness, and instinct.
Just in the past year, I've seen a few truly spectacular undergrads the likes of which I haven't seen before.
They can work autonomously, ask all the right questions, learn on the fly, and somehow have enough time to be at the top of their classes and do self-driven research.
I know, that when I was an undergrad, I was very far below their level.

You can probably predict why this bimodal shift has occurred.
It's the model.

What's happening is that even the 80th percentile undergrads are falling victim to model dependency.
The majority of undergrads are not only preempting their boredom via their phones, but they are also preempting their thoughts via the model.
We often see undergrads that produce reams of code from the model, but are unable to explain what is going on, and more importantly, what are they trying to do.

The elite undergrads are always in control of their own thoughts.
They use the model as just an enhanced search engine, which gives them confidence to enter new areas.
Their knowledge compounds rapidly as they use the model to pull information, but use their own brains to synthesize it.

### Thinking in "Embedding Space"

After talking about undergrads, I must now talk about those 'above' me: *the professor class*.
If you thought professors were speaking in meaningless platitudes before, you haven't seen anything.[^5]
I swear, if I could peer inside the head of a typical professor, I'm sure all I would find is a vector database.

[^5]: There are still some intelligent professors, but among the mediocre, the recent degradation has been extreme

I often joke that professors (and the model) think in "embedding space".
What I mean to say, is that they think as if *embeddings are semantics*.
I can't blame them. After all, if you ask the model, it will claim that *embeddings capture semantics*.

When they speak, they will put words together that *appear* close in the embedding space, but are actually unrelated with respect to their real semantics.
This is just a matter of training data: both for the professor and the model.
Without enough good quality data, embeddings will tend to just capture which words occur together, rather than how they are related.
Of course, a professor should be able to think with grounding, so I can give the model a pass here.

<!--
If insufficient data is available, then the model will emit things that are adjacent in the embedding space. The 'intelligence' appears when the suitable training data exists to actually disambiguate the semantics of words that appear close, but are actually different.
-->

### Biological Frontends for Mr. Model

What could be worse than people becoming dependent on the model?
What if people *became* the model?
Indeed, this is what I witness nowadays.
Professors have become biological frontends for the model.[^6]

[^6]: I don't mean to bash on professors too much. All professions have degraded thusly.

When a student asks for advice, the questions are forwarded to the model, and the model's response comes out of the professor's mouth.
The professor asks the model for research ideas, and then recites the responses to their students.
When reviewing papers for a conference, the PDFs are fed straight into ChatGPT Pro [^7], and the outputs are massaged into the HotCRP boxes.

[^7]: It's research-grade intelligence after all

<!--
paper reviews for their own students, research ideas and criticisms, conference review process lmao
They ask the model first rather than think and the model taints their thinking and makes original thought impossible.
-->

#### Context Pollution

Models suffer from *context pollution*, where garbage can accumulate in its context window that distracts the model from the task its supposed to perform.
Being able to tell what the relevant context is, while discarding the rest, is an essential aspect of intelligence.

If you look at the managerial class in general, they are increasingly falling victim to context pollution.
They attend all kinds of useless meetings and conferences where the executive class jumbles together words that have no relation to each other.
Their heads are filled with words from these continuous meetings and, when they are prompted to discuss something with their subordinates, they bring up unrelated nonsense from their context window.
Buzzword speak has become more and more ubiquitous.

<!--
Context pollution, when some moron says some buzzword it isn't forgotten or contextualized, instead it is brought up over and over again in unrelated contexts just because it has a similar embedding
-->

## "Asking the Model" as Research

Day after day, I will look at my Google Scholar notifications and will see the same paper repeated 100 times.
Here are some recent examples:

- [VerilogMonkey: Exploring Parallel Scaling for Automated Verilog Code Generation with LLMs](https://arxiv.org/pdf/2509.16246)
- [Automated Multi-Agent Workflows for RTL Design](https://arxiv.org/pdf/2509.20182)
- [QuArch: A Question-Answering Dataset for AI Agents in Computer Architecture](https://arxiv.org/abs/2501.01892)
- [AutoChip: Automating HDL Generation Using LLM Feedback](https://arxiv.org/pdf/2311.04887)
- [Chip-Chat: Challenges and Opportunities in Conversational Hardware Design](https://ieeexplore.ieee.org/abstract/document/10299874?)
- [RTLCoder: Fully Open-Source and Efficient LLM-Assisted RTL Code Generation Technique](https://ieeexplore.ieee.org/abstract/document/10720939?)
- [Multi-Agent Reinforcement Learning for Microprocessor Design Space Exploration](https://arxiv.org/pdf/2211.16385)
- [Large Language Monkeys: Scaling Inference Compute with Repeated Sampling](https://arxiv.org/abs/2407.21787)
- [CodeMonkeys: Monkey SWE, Monkey Do](https://scalingintelligence.stanford.edu/blogs/codemonkeys/)

All of these thousands of papers just amount to "asking the model" in a loop, with some scaffolding, some tool use, some "prompt engineering", and perhaps some training data for supervised fine-tuning.
Perhaps some will conduct a beam search across many samples provided to them by Mr. Model.
Perhaps some will construct a new dataset from thin air, which they pose as a "benchmark".

Of course, this LLM mania isn't limited to computer architecture papers.
We see this in all disciplines, where the 'solution' proposed by a paper is "asking Mr. Model", and the 'problem' is whatever fake problem they invent.

Furthermore, due to the high latency of conference paper deadlines and review cycles, by the time a paper is published, its "results" are already suspect.
The authors will have run all their experiments with Mr. Model v7 and by the time the world sees their work, Mr. Model v8 has been released, and large parts of their specialized 'prompting' techniques and scaffolding are made obsolete.

<!--
They will test some problem with Mr. Model v10 and then by the time the paper is done and experiments are final, Mr. Model v11 has been released and everything is done for. So many papers like this.
-->

The problem is that these people have made "asking the model" its own area of research.
Rather than using the model as a productivity booster or powerful search tool to

<!--
produce high impact research products! That is the root of the problem. This is just lazy work.
-->

Why are academics doing this when there are VCs throwing billions of dollars at it. Aren't academics supposed to do things that have both intellectual, logistical, and financial risk? There are no risks here!
LLM for X is lucrative. Just get paid for it!


<!--
Look at "MLArchSys", MLSys, and so forth...
-->

<!--
This isn't the article to rant about the bitter lesson lmao. Leave it for later.
## Sutton's "Bitter Lesson"

- https://www.cs.utexas.edu/~eunsol/courses/data/bitter_lesson.pdf
  - Ahhh the "bitter lesson". Grossly misunderstood and misapplied.
  - It is kind of like the "central limit theorem". Also misunderstood and misapplied.
-->

## "Asking the Model" as a Course

Harvard, Berkeley, Stanford, I'm sure many others are on this same path.

- https://harvard-edge.github.io/cs249r_fall2025/
  - An entirely LLM generated website. This is the most obscene example.
  - https://www.linkedin.com/posts/vijay-janapa-reddi-63a6a173_agentic-ai-for-computer-systems-design-activity-7371588955328155648-DFKl?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAVUAnMBjBFeQj_67eMIA1E2610ABsluQic

Reddi, architecture 2.0 a ripoff from karpathys software 2.0. but reddi! Karpathys recently announced software 3.0! Where's the update? Get with the times! Natural language will be used to generate architectures. The googling moonshot. These people don't appreciate systematic engineering. It's all just a blob for them and they don't wish to interact with the abstractions.


- https://ucbsky.github.io/ucbsky-cs294-264-fall2025/course-website.html
  - "vibe research"
  - Absolutely insane that this is considered 'academic'
  - https://www.linkedin.com/posts/koushik-sen-80b99a_disrupting-systems-research-with-ai-activity-7374945690751447040-5X-h?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAVUAnMBjBFeQj_67eMIA1E2610ABsluQic
  - Add Sagar's class too, but point out that there isn't any extreme "asking the model" insanity directly in the reading list as of yet.
- https://cs329a.stanford.edu/
  - Asking the model in a loop. This isn't that bad compared to the others honestly.
  - https://x.com/Azaliamirh/status/1970610290724339804
  > Very excited to teach CS329A: Self-Improving AI Agents, with @achowdhery for the second time in 2025!


## A Better Path

https://www.linkedin.com/posts/mark-h-r-4837318_nvidiaresearch-ugcPost-7374877258735558656-Vm8H?utm_source=share&utm_medium=member_desktop&rcm=ACoAAAVUAnMBjBFeQj_67eMIA1E2610ABsluQic
This is a counterexample from Mark Ren. He's not just asking the model as the research itself, but he's asking the model to produce a better SAT solver as the main contribution and can discuss what code it generated to produce a better solver. The focus is on the product, not the model. Excellent work.

## Conclusion

Just as one should hesitate when picking up the phone to mitigate a moment of boredom, one must hesitate before shooting a question at the model. Think! Losing boredom is bad enough, losing your sovereignity is even worse.

<!-- At the end of the article, pic of sponge and the ranger, all hail the magic conch! -->

You know what?
Perhaps I'm wrong.
Perhaps "asking the model" is the most useful, impactful, and important thing we can all do today.

In the next few years, I may be the one saying:

> **Squidward**: *All hail the Magic Conch*

{{ image(path="club_spongebob_16.webp", class="inset") }}
